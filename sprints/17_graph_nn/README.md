# Sprint 17: Diving into Graph Neural Networks (GNNs)

**Focus:** Understanding and implementing Graph Neural Networks, specifically Graph Convolutional Networks (GCNs) and GraphSAGE, and exploring dynamic Knowledge Graph construction.

## Goals
- Understand the fundamentals of GNNs and message passing.
- Implement a GCN for node classification.
- Create documentation explaining GCN concepts.
- Develop a pipeline to dynamically build a Knowledge Graph from text and update GNN embeddings.

## Tasks & Results

- [x] **Implement GCN for Node Classification:**
    - Used PyTorch Geometric to build a GCN model.
    - Trained the model on the Zachary's Karate Club dataset for semi-supervised node classification.
    - Visualized node embeddings using t-SNE.
    - **Result:** [`results/train_gcn_zach_karate_club.py`](results/train_gcn_zach_karate_club.py)
    - **Visualization:** `results/tsne_karate_club.png` (Generated by the script)

- [x] **Explain GCN Concepts:**
    - Wrote a detailed explanation of GCNs, message passing, and the Karate Club example code.
    - **Result:** [`docs/gcn_explanation.md`](docs/gcn_explanation.md)

- [x] **Develop Dynamic KG & GNN Pipeline:**
    - Created a script that extracts Subject-Verb-Object (SVO) triples from text events using an LLM (`gpt-4.1-nano` via `litellm`).
    - Dynamically updated a `networkx` graph based on extracted triples.
    - Implemented entity canonicalization/registration logic.
    - Used a GraphSAGE model to compute node embeddings based on the dynamic graph structure.
    - Indexed node embeddings using Faiss for similarity search (though search wasn't explicitly used in the final script version shown).
    - **Result:** [`results/dynamic_kg_gnn.py`](results/dynamic_kg_gnn.py)

## Learnings & Reflections
- Gained practical experience with PyTorch Geometric for GNN implementation.
- Understood the core message-passing paradigm in GNNs.
- Explored challenges in dynamic Knowledge Graph construction, including entity extraction and canonicalization.
- Integrated LLMs (for triple extraction), graph databases (`networkx`), GNNs (GraphSAGE via PyG), and vector stores (Faiss) into a single pipeline.

## Next Steps / Backlog Considerations
- Explore more complex GNN architectures (e.g., GAT).
- Implement actual RAG or querying capabilities using the Faiss index populated by the dynamic GNN embeddings.
- Investigate more robust entity linking/canonicalization techniques.
- Apply the dynamic KG pipeline to a larger stream of text data. 